import os
import time
import torch
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import griddata
from utilities import create_save_path, gradients, Sampler, to_numpy, relative_error, wn_linear, mean_squared_error, to_device


torch.manual_seed(42)
np.random.seed(42)

# domain
bound_l = 0
bound_r = 1
bound_t = 1
bound_d = 0
layers = [2, 50, 50, 50, 1]
batch_size = 10000
bound_weight = 1
ic_weight = 1


class NeuralNetwork(torch.nn.Module):
    def __init__(self, X, layers, device):
        super().__init__()
        # build network
        self.device = torch.device(device)
        self.X_mean = X.mean(0, keepdims=True).to(self.device)
        self.X_std = X.std(0, keepdims=True).to(self.device)
        self.fnn = torch.nn.Sequential().to(self.device)
        for i in range(len(layers) - 2):
            self.fnn.add_module('dense_%d' % i, wn_linear(layers[i], layers[i + 1]).to(self.device))
            self.fnn.add_module('tanh_%d' % i, torch.nn.Tanh())
        self.fnn.add_module('dense_output', wn_linear(layers[-2], layers[-1]).to(self.device))

    def forward(self, X):
        H = (X - self.X_mean) / self.X_std
        out = self.fnn(H)
        return out


class PINNWave2D:
    def __init__(self, network, dataset, batch_size=10000, bound_weight=1, ic_weight=1, log_path=None,
                 model_path=None, pic_path=None, device="cuda:0"):
        self.device = torch.device(device)
        self.network = network.to(self.device)
        self.dataset = dataset
        self.batch_size = batch_size
        self.bound_weight = bound_weight
        self.ic_weight = ic_weight
        self.log_path = log_path
        self.model_path = model_path
        self.pic_path = pic_path

    def train(self, lr_rate, decay_factor, total_it, print_it, evaluate_it, pic_it, lr_it):
        optimizer = torch.optim.Adam(self.network.parameters(), lr=lr_rate)
        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, decay_factor)
        self.logging('\nstart training...')
        tic = time.time()
        min_l2 = 99999
        time1 = time.time()

        for it in range(total_it):
            loss_pde = self.pde_loss()
            loss_bc = self.boundary_loss()
            loss_ic = self.ic_loss()
            loss_ic_der = self.ic_der_loss()
            loss = (loss_pde + self.bound_weight * loss_bc + self.ic_weight *
                    loss_ic + self.ic_weight * loss_ic_der)

            # backpropagation
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if it % print_it == 0:
                self.logging(f'it {it}: loss {loss:.3e}, pde_loss {loss_pde:.3e}, '
                             f'loss_bc {loss_bc:.3e},  loss_ic {loss_ic:.3e}, loss_ic_der {loss_ic_der:.3e}')

            # evaluate
            if it and it % evaluate_it == 0:
                time2 = time.time()
                self.logging(f'training time is:{time2 - time1}')
                time1 = time2
                l2_error = self.evaluation()

                # save model
                if l2_error < min_l2:
                    min_l2 = l2_error
                    self.save_model(it, min_l2)

            # save picture
            if it and it % pic_it == 0:
                self.save_pic(it)


            # update learning rate
            if it and it % lr_it == 0:
                scheduler.step()
                self.logging("Update learning rate, lr: %2e" % scheduler.get_last_lr()[0])

        toc = time.time()
        self.logging(f'total training time: {toc - tic}')

    def pde_loss(self):
        # get mini batch in domain
        X_pde, _ = self.dataset.get_pde_batch(self.batch_size)
        X_pde = X_pde.requires_grad_(True).to(self.device)
        u_pred = self.network(X_pde)
        residual = self.dataset.residual(X_pde, u_pred)
        return mean_squared_error(residual, 0)

    def boundary_loss(self):
        # get mini batch in boundary
        X_bound = self.dataset.get_bound_batch(self.batch_size)
        X_bound = X_bound.to(self.device)
        u_pred = self.network(X_bound)
        return mean_squared_error(u_pred, 0)

    def ic_loss(self):
        X_ic, u_ic = self.dataset.get_ic_batch(self.batch_size)
        X_ic = X_ic.requires_grad_(True).to(self.device)
        u_pred = self.network(X_ic)
        return mean_squared_error(u_pred, u_ic.to(self.device))

    def ic_der_loss(self):
        X_ic, u_ic = self.dataset.get_ic_batch(self.batch_size)
        X_ic = X_ic.requires_grad_(True).to(self.device)
        u_pred = self.network(X_ic)
        u_x = gradients(u_pred, X_ic)[:, 0:1]
        return mean_squared_error(u_x, 0)

    def predict(self, X):  # prediction with no gradients
        with torch.no_grad():
            Y_pred = self.network(X.to(self.device) )
        return Y_pred

    def evaluation(self):
        self.network.eval()
        # get mini batch for test
        X_test, U_test = self.dataset.get_test_batch(self.batch_size)
        # predict U
        U_pred = self.predict(X_test.to(self.device))
        # compute l2 error
        error = relative_error(U_pred, U_test.to(self.device))
        self.logging(f'l2 related error: {error:.3e}')
        self.network.train()
        return error.item()

    def logging(self, log_item):
        # write into consolo and file
        with open(self.log_path, 'a+') as log:
            log.write(log_item + '\n')
        print(log_item)

    def save_model(self, step, l2):
        torch.save({'step': step, 'model': self.network.state_dict(), 'l2_error': l2}, self.model_path)
        log_item = "Model checkpoint successful saved in %s" % self.model_path
        self.logging(log_item)

    def save_pic(self, it):
        # get image data
        x1, x2, X_star, U_star = self.dataset.get_img_batch(self.batch_size)
        # # (100, 100) (100, 100) (10000, 2) (10000, 1)
        # predict U
        U_pred = self.predict(torch.tensor(X_star, dtype=torch.float32).to(self.device))
        # rearrange data
        U_star = griddata(X_star, U_star.flatten(), (x1, x2), method='cubic')
        U_pred = griddata(X_star, to_numpy(U_pred).flatten(), (x1, x2), method='cubic')
        # print(x1.shape, x2.shape, X_star.shape, U_star.shape, U_pred.shape)
        # (100, 100) (100, 100) (10000, 2) (100, 100) (100, 100)
        plt.figure(1, figsize=(18, 5))

        # draw pic for real u
        plt.subplot(1, 3, 1)
        plt.pcolor(x1, x2, U_star, cmap='jet')
        plt.colorbar()
        plt.xlabel(r'$x$')
        plt.ylabel(r'$y$')
        plt.title('Exact $u(x,y)$')
        # draw pic for Predicted u
        plt.subplot(1, 3, 2)
        plt.pcolor(x1, x2, U_pred, cmap='jet')
        plt.colorbar()
        plt.xlabel(r'$x$')
        plt.ylabel(r'$y$')
        plt.title('Predicted $u(x,y)$')

        # draw pic for Absolute error
        plt.subplot(1, 3, 3)
        plt.pcolor(x1, x2, np.abs(U_star - U_pred), cmap='jet')
        plt.colorbar()
        plt.xlabel(r'$x$')
        plt.ylabel(r'$y$')
        plt.title('Absolute error')
        plt.tight_layout()

        # save pictures
        fig_path = "test_%d.jpg" % (it)
        plt.savefig(os.path.join(self.pic_path, fig_path))
        self.logging("Pictures has been successfully saved in %s" % os.path.join(self.pic_path, fig_path))
        plt.close('all')


class DatasetWave2D:
    def __init__(self, bound_l, bound_r, bound_t, bound_d):
        self.bound_l = bound_l
        self.bound_r = bound_r
        self.bound_t = bound_t
        self.bound_d = bound_d
        self.device = torch.device(device)

        # Domain boundaries 下 上 左
        bc1_coords = np.array([[self.bound_l, self.bound_d], [self.bound_r, self.bound_d]])
        bc2_coords = np.array([[self.bound_r, self.bound_t], [self.bound_l, self.bound_t]])
        ic_coords = np.array([[self.bound_l, self.bound_t], [self.bound_l, self.bound_d]])
        dom_coords = np.array([[self.bound_l, self.bound_d], [self.bound_r, self.bound_t]])

        # Create boundary conditions samplers
        self.bc1_sampler = Sampler(2, bc1_coords, lambda x: self.u(x), name='Dirichlet BC1')
        self.bc2_sampler = Sampler(2, bc2_coords, lambda x: self.u(x), name='Dirichlet BC2')
        self.ic_sampler = Sampler(2, ic_coords, lambda x: self.ic_u(x), name='Dirichlet BC3')

        # Create residual sampler
        self.pde_sampler = Sampler(2, dom_coords, lambda x: self.u(x), name='Forcing')

    def u(self, x):
        # ground truth 解析解
        return np.cos(2 * np.pi * x[:, 0]) * np.sin(np.pi * x[:, 1]) + 0.5 * np.cos(8 * np.pi * x[:, 0]) * np.sin(4 * np.pi * x[:, 1])

    def ic_u(self, x):
        return np.sin(np.pi * x[:, 1]) + 0.5 * np.sin(4 * np.pi * x[:, 1])

    def residual(self, X, u):
        u_x = gradients(u, X)[:, 0:1]
        u_y = gradients(u, X)[:, 1:2]
        u_xx = gradients(u_x, X)[:, 0:1]
        u_yy = gradients(u_y, X)[:, 1:2]
        residual = u_xx - 4 * u_yy
        return residual

    def get_pde_batch(self, N):
        # sample points from training domain, residual = f
        pde_x, pde_f = self.pde_sampler.sample(N)
        return (torch.tensor(pde_x, dtype=torch.float32).to(self.device),
                torch.tensor(pde_f, dtype=torch.float32).to(self.device))

    def get_ic_batch(self, N):
        # sample points from initial condition
        ic_x, ic_u = self.ic_sampler.sample(N)
        return (torch.tensor(ic_x, dtype=torch.float32).to(self.device),
                torch.tensor(ic_u, dtype=torch.float32).to(self.device))

    def get_bound_batch(self, N):
        N = N // 2
        # sample points from boundary
        bc1_x, bc1_u = self.bc1_sampler.sample(N)
        bc2_x, bc2_u = self.bc2_sampler.sample(N)
        # rearrange data
        bc_x = np.concatenate([bc1_x, bc2_x])
        return torch.tensor(bc_x, dtype=torch.float32).to(self.device)

    def get_test_batch(self, N):
        # sample batch for test
        nn = int(N ** (0.5))
        # generate mesh
        x1 = np.linspace(self.bound_l, self.bound_r, nn)[:, None]
        x2 = np.linspace(self.bound_d, self.bound_t, nn)[:, None]
        x1, x2 = np.meshgrid(x1, x2)
        x_star = np.hstack((x1.flatten()[:, None], x2.flatten()[:, None]))
        u_star = self.u(x_star)
        return (torch.tensor(x_star, dtype=torch.float32).to(self.device),
                torch.tensor(u_star, dtype=torch.float32).to(self.device))

    def get_img_batch(self, N):
        N = int(N ** 0.5)
        # generate mesh
        x1 = np.linspace(self.bound_l, self.bound_r, N)[:, None]
        x2 = np.linspace(self.bound_d, self.bound_t, N)[:, None]
        x1, x2 = np.meshgrid(x1, x2)
        # rearrange data
        x_star = np.hstack((x1.flatten()[:, None], x2.flatten()[:, None]))
        u_star = self.u(x_star)
        return x1, x2, x_star, u_star


if __name__ == '__main__':
    # load device
    device = torch.device(f"cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Use GPU: {torch.cuda.is_available()}\n")
    # create save path
    save_path = "../output/Wave2D/Vanilla PINN/"
    log_path, model_path, pic_path = create_save_path(save_path)
    # load dataset
    dataset = DatasetWave2D(bound_l, bound_r, bound_t, bound_d)
    X_star, U_star = dataset.get_test_batch(batch_size)
    # create model
    network = NeuralNetwork(X_star, layers, device).to(device)
    pinn = PINNWave2D(network, dataset, batch_size, bound_weight, ic_weight,log_path, model_path, pic_path, device)
    # train model
    pinn.train(lr_rate=1e-3, decay_factor=0.5, total_it=35010, print_it=10, evaluate_it=100, pic_it=1000, lr_it=10000)
